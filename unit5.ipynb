{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D3NL_e4crQv"
      },
      "source": [
        "# Unit 5: An Introduction to ML-Agents\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97ZiytXEgqIz"
      },
      "source": [
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/thumbnail.png\" alt=\"Thumbnail\"/>\n",
        "\n",
        "In this notebook, you'll learn about ML-Agents and train two agents.\n",
        "\n",
        "- The first one will learn to **shoot snowballs onto spawning targets**.\n",
        "- The second need to press a button to spawn a pyramid, then navigate to the pyramid, knock it over, **and move to the gold brick at the top**. To do that, it will need to explore its environment, and we will use a technique called curiosity.\n",
        "\n",
        "After that, you'll be able **to watch your agents playing directly on your browser**.\n",
        "\n",
        "For more information about the certification process, check this section üëâ https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMYrDriDujzX"
      },
      "source": [
        "‚¨áÔ∏è Here is an example of what **you will achieve at the end of this unit.** ‚¨áÔ∏è\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBmFlh8suma-"
      },
      "source": [
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/pyramids.gif\" alt=\"Pyramids\"/>\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/snowballtarget.gif\" alt=\"SnowballTarget\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-cYE0K5iL-w"
      },
      "source": [
        "### üéÆ Environments:\n",
        "\n",
        "- [Pyramids](https://github.com/Unity-Technologies/ml-agents/blob/main/docs/Learning-Environment-Examples.md#pyramids)\n",
        "- SnowballTarget\n",
        "\n",
        "### üìö RL-Library:\n",
        "\n",
        "- [ML-Agents](https://github.com/Unity-Technologies/ml-agents)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEhtaFh9i31S"
      },
      "source": [
        "We're constantly trying to improve our tutorials, so **if you find some issues in this notebook**, please [open an issue on the GitHub Repo](https://github.com/huggingface/deep-rl-class/issues)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7f63r3Yi5vE"
      },
      "source": [
        "## Objectives of this notebook üèÜ\n",
        "\n",
        "At the end of the notebook, you will:\n",
        "\n",
        "- Understand how works **ML-Agents**, the environment library.\n",
        "- Be able to **train agents in Unity Environments**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viNzVbVaYvY3"
      },
      "source": [
        "## This notebook is from the Deep Reinforcement Learning Course\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/deep-rl-course-illustration.jpg\" alt=\"Deep RL Course illustration\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6p5HnEefISCB"
      },
      "source": [
        "In this free course, you will:\n",
        "\n",
        "- üìñ Study Deep Reinforcement Learning in **theory and practice**.\n",
        "- üßë‚Äçüíª Learn to **use famous Deep RL libraries** such as Stable Baselines3, RL Baselines3 Zoo, CleanRL and Sample Factory 2.0.\n",
        "- ü§ñ Train **agents in unique environments**\n",
        "\n",
        "And more check üìö the syllabus üëâ https://huggingface.co/deep-rl-course/communication/publishing-schedule\n",
        "\n",
        "Don‚Äôt forget to **<a href=\"http://eepurl.com/ic5ZUD\">sign up to the course</a>** (we are collecting your email to be able to¬†**send you the links when each Unit is published and give you information about the challenges and updates).**\n",
        "\n",
        "\n",
        "The best way to keep in touch is to join our discord server to exchange with the community and with us üëâüèª https://discord.gg/ydHrjt3WP5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-mo_6rXIjRi"
      },
      "source": [
        "## Prerequisites üèóÔ∏è\n",
        "Before diving into the notebook, you need to:\n",
        "\n",
        "üî≤ üìö **Study [what is ML-Agents and how it works by reading Unit 5](https://huggingface.co/deep-rl-course/unit5/introduction)**  ü§ó  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYO1uD5Ujgdh"
      },
      "source": [
        "# Let's train our agents üöÄ\n",
        "\n",
        "**To validate this hands-on for the certification process, you just need to push your trained models to the Hub**. There‚Äôs no results to attain to validate this one. But if you want to get nice results you can try to attain:\n",
        "\n",
        "- For `Pyramids` : Mean Reward = 1.75\n",
        "- For `SnowballTarget` : Mean Reward = 15 or 30 targets hit in an episode.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DssdIjk_8vZE"
      },
      "source": [
        "## Set the GPU üí™\n",
        "- To **accelerate the agent's training, we'll use a GPU**. To do that, go to `Runtime > Change Runtime type`\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/gpu-step1.jpg\" alt=\"GPU Step 1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTfCXHy68xBv"
      },
      "source": [
        "- `Hardware Accelerator > GPU`\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/gpu-step2.jpg\" alt=\"GPU Step 2\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "an3ByrXYQ4iK"
      },
      "source": [
        "## Clone the repository and install the dependencies üîΩ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6WNoL04M7rTa"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Clone the repository\n",
        "!git clone --depth 1 https://github.com/Unity-Technologies/ml-agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "d8wmVcMk7xKo"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Go inside the repository and install the package\n",
        "%cd ml-agents\n",
        "!pip3 install -e ./ml-agents-envs\n",
        "!pip3 install -e ./ml-agents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5_7Ptd_kEcG"
      },
      "source": [
        "## SnowballTarget ‚õÑ\n",
        "\n",
        "If you need a refresher on how this environments work check this section üëâ\n",
        "https://huggingface.co/deep-rl-course/unit5/snowball-target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRY5ufKUKfhI"
      },
      "source": [
        "### Download and move the environment zip file in `./training-envs-executables/linux/`\n",
        "- Our environment executable is in a zip file.\n",
        "- We need to download it and place it to `./training-envs-executables/linux/`\n",
        "- We use a linux executable because we use colab, and colab machines OS is Ubuntu (linux)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "C9Ls6_6eOKiA"
      },
      "outputs": [],
      "source": [
        "# Here, we create training-envs-executables and linux\n",
        "!mkdir ./training-envs-executables\n",
        "!mkdir ./training-envs-executables/linux"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsoZGxr1MIXY"
      },
      "source": [
        "Download the file SnowballTarget.zip from https://drive.google.com/file/d/1YHHLjyj6gaZ3Gemx1hQgqrPgSS2ZhmB5 using `wget`.\n",
        "\n",
        "Check out the full solution to download large files from GDrive [here](https://bcrf.biochem.wisc.edu/2021/02/05/download-google-drive-files-using-wget/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QU6gi8CmWhnA",
        "outputId": "6f8df29d-e6cd-41de-f6eb-74b2a33d1a60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-01-19 05:06:34--  https://docs.google.com/uc?export=download&confirm=&id=1YHHLjyj6gaZ3Gemx1hQgqrPgSS2ZhmB5\n",
            "Resolving docs.google.com (docs.google.com)... 142.251.2.101, 142.251.2.100, 142.251.2.139, ...\n",
            "Connecting to docs.google.com (docs.google.com)|142.251.2.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1YHHLjyj6gaZ3Gemx1hQgqrPgSS2ZhmB5&export=download [following]\n",
            "--2024-01-19 05:06:34--  https://drive.usercontent.google.com/download?id=1YHHLjyj6gaZ3Gemx1hQgqrPgSS2ZhmB5&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 142.251.2.132, 2607:f8b0:4023:c0d::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|142.251.2.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2429 (2.4K) [text/html]\n",
            "Saving to: ‚Äò./training-envs-executables/linux/SnowballTarget.zip‚Äô\n",
            "\n",
            "./training-envs-exe 100%[===================>]   2.37K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-19 05:06:34 (31.1 MB/s) - ‚Äò./training-envs-executables/linux/SnowballTarget.zip‚Äô saved [2429/2429]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1YHHLjyj6gaZ3Gemx1hQgqrPgSS2ZhmB5' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1YHHLjyj6gaZ3Gemx1hQgqrPgSS2ZhmB5\" -O ./training-envs-executables/linux/SnowballTarget.zip && rm -rf /tmp/cookies.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LLVaEEK3ayi"
      },
      "source": [
        "We unzip the executable.zip file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4tkOjtLPGvX",
        "outputId": "65747392-c415-4ce3-aea6-3b5a307fd552"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SnowballTarget.zip\n"
          ]
        }
      ],
      "source": [
        "!ls ./training-envs-executables/linux/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8FPx0an9IAwO"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!unzip -d ./training-envs-executables/linux/ ./training-envs-executables/linux/SnowballTarget.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tCdzr2_PWAY"
      },
      "source": [
        "*Make* sure your file is accessible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "EdFsLJ11JvQf"
      },
      "outputs": [],
      "source": [
        "!chmod -R 755 ./training-envs-executables/linux"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAuEq32Mwvtz"
      },
      "source": [
        "### Define the SnowballTarget config file\n",
        "- In ML-Agents, you define the **training hyperparameters into config.yaml files.**\n",
        "\n",
        "There are multiple hyperparameters. To know them better, you should check for each explanation with [the documentation](https://github.com/Unity-Technologies/ml-agents/blob/release_20_docs/docs/Training-Configuration-File.md)\n",
        "\n",
        "\n",
        "So you need to create a `SnowballTarget.yaml` config file in ./content/ml-agents/config/ppo/\n",
        "\n",
        "We'll give you here a first version of this config (to copy and paste into your `SnowballTarget.yaml file`), **but you should modify it**.\n",
        "\n",
        "```\n",
        "behaviors:\n",
        "  SnowballTarget:\n",
        "    trainer_type: ppo\n",
        "    summary_freq: 10000\n",
        "    keep_checkpoints: 10\n",
        "    checkpoint_interval: 50000\n",
        "    max_steps: 200000\n",
        "    time_horizon: 64\n",
        "    threaded: true\n",
        "    hyperparameters:\n",
        "      learning_rate: 0.0003\n",
        "      learning_rate_schedule: linear\n",
        "      batch_size: 128\n",
        "      buffer_size: 2048\n",
        "      beta: 0.005\n",
        "      epsilon: 0.2\n",
        "      lambd: 0.95\n",
        "      num_epoch: 3\n",
        "    network_settings:\n",
        "      normalize: false\n",
        "      hidden_units: 256\n",
        "      num_layers: 2\n",
        "      vis_encode_type: simple\n",
        "    reward_signals:\n",
        "      extrinsic:\n",
        "        gamma: 0.99\n",
        "        strength: 1.0\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4U3sRH4N4h_l"
      },
      "source": [
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/snowballfight_config1.png\" alt=\"Config SnowballTarget\"/>\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/snowballfight_config2.png\" alt=\"Config SnowballTarget\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJJdo_5AyoGo"
      },
      "source": [
        "As an experimentation, you should also try to modify some other hyperparameters. Unity provides very [good documentation explaining each of them here](https://github.com/Unity-Technologies/ml-agents/blob/main/docs/Training-Configuration-File.md).\n",
        "\n",
        "Now that you've created the config file and understand what most hyperparameters do, we're ready to train our agent üî•."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9fI555bO12v"
      },
      "source": [
        "### Train the agent\n",
        "\n",
        "To train our agent, we just need to **launch mlagents-learn and select the executable containing the environment.**\n",
        "\n",
        "We define four parameters:\n",
        "\n",
        "1. `mlagents-learn <config>`: the path where the hyperparameter config file is.\n",
        "2. `--env`: where the environment executable is.\n",
        "3. `--run_id`: the name you want to give to your training run id.\n",
        "4. `--no-graphics`: to not launch the visualization during the training.\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/mlagentslearn.png\" alt=\"MlAgents learn\"/>\n",
        "\n",
        "Train the model and use the `--resume` flag to continue training in case of interruption.\n",
        "\n",
        "> It will fail first time if and when you use `--resume`, try running the block again to bypass the error.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lN32oWF8zPjs"
      },
      "source": [
        "The training will take 10 to 35min depending on your config, go take a ‚òïÔ∏èyou deserve it ü§ó."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUvv_0XLP8mt",
        "outputId": "1dc74182-a2f1-44fb-98fc-4a33ce80ab2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3DBallHard.yaml        FoodCollector.yaml  PyramidsRND.yaml\t   VisualFoodCollector.yaml\n",
            "3DBall_randomize.yaml  GridWorld.yaml\t   Pyramids.yaml\t   Walker.yaml\n",
            "3DBall.yaml\t       Hallway.yaml\t   SnowballTarget.yaml\t   WallJump_curriculum.yaml\n",
            "Basic.yaml\t       Match3.yaml\t   Sorter_curriculum.yaml  WallJump.yaml\n",
            "Crawler.yaml\t       PushBlock.yaml\t   Visual3DBall.yaml\t   Worm.yaml\n"
          ]
        }
      ],
      "source": [
        "!ls ./config/ppo/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS-Yh1UdHfzy",
        "outputId": "d90583f9-07e0-4286-a3a8-1296b8c539e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:451.)\n",
            "  _C._set_default_tensor_type(t)\n",
            "2024-01-20 12:11:02.781759: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-01-20 12:11:03.863875: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "            ‚îê  ‚ïñ\n",
            "        ‚ïì‚ïñ‚ï¨‚îÇ‚ï°  ‚îÇ‚îÇ‚ï¨‚ïñ‚ïñ\n",
            "    ‚ïì‚ïñ‚ï¨‚îÇ‚îÇ‚îÇ‚îÇ‚îÇ‚îò  ‚ï¨‚îÇ‚îÇ‚îÇ‚îÇ‚îÇ‚ï¨‚ïñ\n",
            " ‚ïñ‚ï¨‚îÇ‚îÇ‚îÇ‚îÇ‚îÇ‚ï¨‚ïú        ‚ïô‚ï¨‚îÇ‚îÇ‚îÇ‚îÇ‚îÇ‚ïñ‚ïñ                               ‚ïó‚ïó‚ïó\n",
            " ‚ï¨‚ï¨‚ï¨‚ï¨‚ïñ‚îÇ‚îÇ‚ï¶‚ïñ        ‚ïñ‚ï¨‚îÇ‚îÇ‚ïó‚ï£‚ï£‚ï£‚ï¨      ‚ïü‚ï£‚ï£‚ï¨    ‚ïü‚ï£‚ï£‚ï£             ‚ïú‚ïú‚ïú  ‚ïü‚ï£‚ï£\n",
            " ‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ïñ‚îÇ‚ï¨‚ïñ‚ïñ‚ïì‚ï¨‚ï™‚îÇ‚ïì‚ï£‚ï£‚ï£‚ï£‚ï£‚ï£‚ï£‚ï¨      ‚ïü‚ï£‚ï£‚ï¨    ‚ïü‚ï£‚ï£‚ï£ ‚ïí‚ï£‚ï£‚ïñ‚ïó‚ï£‚ï£‚ï£‚ïó   ‚ï£‚ï£‚ï£ ‚ï£‚ï£‚ï£‚ï£‚ï£‚ï£ ‚ïü‚ï£‚ï£‚ïñ   ‚ï£‚ï£‚ï£\n",
            " ‚ï¨‚ï¨‚ï¨‚ï¨‚îê  ‚ïô‚ï¨‚ï¨‚ï¨‚ï¨‚îÇ‚ïì‚ï£‚ï£‚ï£‚ïù‚ïú  ‚ï´‚ï£‚ï£‚ï£‚ï¨      ‚ïü‚ï£‚ï£‚ï¨    ‚ïü‚ï£‚ï£‚ï£ ‚ïü‚ï£‚ï£‚ï£‚ïô ‚ïô‚ï£‚ï£‚ï£  ‚ï£‚ï£‚ï£ ‚ïô‚ïü‚ï£‚ï£‚ïú‚ïô  ‚ï´‚ï£‚ï£  ‚ïü‚ï£‚ï£\n",
            " ‚ï¨‚ï¨‚ï¨‚ï¨‚îê     ‚ïô‚ï¨‚ï¨‚ï£‚ï£      ‚ï´‚ï£‚ï£‚ï£‚ï¨      ‚ïü‚ï£‚ï£‚ï¨    ‚ïü‚ï£‚ï£‚ï£ ‚ïü‚ï£‚ï£‚ï¨   ‚ï£‚ï£‚ï£  ‚ï£‚ï£‚ï£  ‚ïü‚ï£‚ï£     ‚ï£‚ï£‚ï£‚îå‚ï£‚ï£‚ïú\n",
            " ‚ï¨‚ï¨‚ï¨‚ïú       ‚ï¨‚ï¨‚ï£‚ï£      ‚ïô‚ïù‚ï£‚ï£‚ï¨      ‚ïô‚ï£‚ï£‚ï£‚ïó‚ïñ‚ïì‚ïó‚ï£‚ï£‚ï£‚ïú ‚ïü‚ï£‚ï£‚ï¨   ‚ï£‚ï£‚ï£  ‚ï£‚ï£‚ï£  ‚ïü‚ï£‚ï£‚ï¶‚ïì    ‚ï£‚ï£‚ï£‚ï£‚ï£\n",
            " ‚ïô   ‚ïì‚ï¶‚ïñ    ‚ï¨‚ï¨‚ï£‚ï£   ‚ïì‚ïó‚ïó‚ïñ            ‚ïô‚ïù‚ï£‚ï£‚ï£‚ï£‚ïù‚ïú   ‚ïò‚ïù‚ïù‚ïú   ‚ïù‚ïù‚ïù  ‚ïù‚ïù‚ïù   ‚ïô‚ï£‚ï£‚ï£    ‚ïü‚ï£‚ï£‚ï£\n",
            "   ‚ï©‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¶‚ï¶‚ï¨‚ï¨‚ï£‚ï£‚ïó‚ï£‚ï£‚ï£‚ï£‚ï£‚ï£‚ï£‚ïù                                             ‚ï´‚ï£‚ï£‚ï£‚ï£\n",
            "      ‚ïô‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï£‚ï£‚ï£‚ï£‚ï£‚ï£‚ïù‚ïú\n",
            "          ‚ïô‚ï¨‚ï¨‚ï¨‚ï£‚ï£‚ï£‚ïú\n",
            "             ‚ïô\n",
            "        \n",
            " Version information:\n",
            "  ml-agents: 1.1.0.dev0,\n",
            "  ml-agents-envs: 1.1.0.dev0,\n",
            "  Communicator API: 1.5.0,\n",
            "  PyTorch: 2.1.2+cu121\n",
            "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
            "[INFO] Connected new brain: SnowballTarget?team=0\n",
            "[INFO] Hyperparameters for behavior name SnowballTarget: \n",
            "\ttrainer_type:\tppo\n",
            "\thyperparameters:\t\n",
            "\t  batch_size:\t128\n",
            "\t  buffer_size:\t2048\n",
            "\t  learning_rate:\t0.0004\n",
            "\t  beta:\t0.005\n",
            "\t  epsilon:\t0.2\n",
            "\t  lambd:\t0.95\n",
            "\t  num_epoch:\t5\n",
            "\t  shared_critic:\tFalse\n",
            "\t  learning_rate_schedule:\tlinear\n",
            "\t  beta_schedule:\tlinear\n",
            "\t  epsilon_schedule:\tlinear\n",
            "\tcheckpoint_interval:\t50000\n",
            "\tnetwork_settings:\t\n",
            "\t  normalize:\tFalse\n",
            "\t  hidden_units:\t256\n",
            "\t  num_layers:\t4\n",
            "\t  vis_encode_type:\tsimple\n",
            "\t  memory:\tNone\n",
            "\t  goal_conditioning_type:\thyper\n",
            "\t  deterministic:\tFalse\n",
            "\treward_signals:\t\n",
            "\t  extrinsic:\t\n",
            "\t    gamma:\t0.99\n",
            "\t    strength:\t1.0\n",
            "\t    network_settings:\t\n",
            "\t      normalize:\tFalse\n",
            "\t      hidden_units:\t128\n",
            "\t      num_layers:\t2\n",
            "\t      vis_encode_type:\tsimple\n",
            "\t      memory:\tNone\n",
            "\t      goal_conditioning_type:\thyper\n",
            "\t      deterministic:\tFalse\n",
            "\tinit_path:\tNone\n",
            "\tkeep_checkpoints:\t10\n",
            "\teven_checkpoints:\tFalse\n",
            "\tmax_steps:\t1000000\n",
            "\ttime_horizon:\t64\n",
            "\tsummary_freq:\t10000\n",
            "\tthreaded:\tTrue\n",
            "\tself_play:\tNone\n",
            "\tbehavioral_cloning:\tNone\n",
            "[INFO] SnowballTarget. Step: 10000. Time Elapsed: 48.076 s. Mean Reward: 3.818. Std of Reward: 1.825. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 10000. Time Elapsed: 48.076 s. Mean Reward: 3.818. Std of Reward: 1.825. Training.\n",
            "[INFO] SnowballTarget. Step: 20000. Time Elapsed: 93.510 s. Mean Reward: 6.600. Std of Reward: 2.714. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 20000. Time Elapsed: 93.510 s. Mean Reward: 6.600. Std of Reward: 2.714. Training.\n",
            "[INFO] SnowballTarget. Step: 30000. Time Elapsed: 134.300 s. Mean Reward: 9.636. Std of Reward: 3.458. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 30000. Time Elapsed: 134.300 s. Mean Reward: 9.636. Std of Reward: 3.458. Training.\n",
            "[INFO] SnowballTarget. Step: 40000. Time Elapsed: 177.134 s. Mean Reward: 11.673. Std of Reward: 2.465. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 40000. Time Elapsed: 177.134 s. Mean Reward: 11.673. Std of Reward: 2.465. Training.\n",
            "[INFO] SnowballTarget. Step: 50000. Time Elapsed: 217.880 s. Mean Reward: 13.045. Std of Reward: 3.082. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 50000. Time Elapsed: 217.880 s. Mean Reward: 13.045. Std of Reward: 3.082. Training.\n",
            "[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-49936.onnx\n",
            "INFO:mlagents.trainers.torch_entities.model_serialization:Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-49936.onnx\n",
            "[INFO] SnowballTarget. Step: 60000. Time Elapsed: 260.548 s. Mean Reward: 15.418. Std of Reward: 2.469. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 60000. Time Elapsed: 260.548 s. Mean Reward: 15.418. Std of Reward: 2.469. Training.\n",
            "[INFO] SnowballTarget. Step: 70000. Time Elapsed: 298.783 s. Mean Reward: 16.795. Std of Reward: 3.195. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 70000. Time Elapsed: 298.783 s. Mean Reward: 16.795. Std of Reward: 3.195. Training.\n",
            "[INFO] SnowballTarget. Step: 80000. Time Elapsed: 343.237 s. Mean Reward: 17.582. Std of Reward: 2.668. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 80000. Time Elapsed: 343.237 s. Mean Reward: 17.582. Std of Reward: 2.668. Training.\n",
            "[INFO] SnowballTarget. Step: 90000. Time Elapsed: 381.965 s. Mean Reward: 19.341. Std of Reward: 3.030. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 90000. Time Elapsed: 381.965 s. Mean Reward: 19.341. Std of Reward: 3.030. Training.\n",
            "[INFO] SnowballTarget. Step: 100000. Time Elapsed: 426.501 s. Mean Reward: 20.873. Std of Reward: 2.867. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 100000. Time Elapsed: 426.501 s. Mean Reward: 20.873. Std of Reward: 2.867. Training.\n",
            "[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-99960.onnx\n",
            "INFO:mlagents.trainers.torch_entities.model_serialization:Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-99960.onnx\n",
            "[INFO] SnowballTarget. Step: 110000. Time Elapsed: 471.752 s. Mean Reward: 22.815. Std of Reward: 2.681. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 110000. Time Elapsed: 471.752 s. Mean Reward: 22.815. Std of Reward: 2.681. Training.\n",
            "[INFO] SnowballTarget. Step: 120000. Time Elapsed: 519.186 s. Mean Reward: 23.289. Std of Reward: 3.390. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 120000. Time Elapsed: 519.186 s. Mean Reward: 23.289. Std of Reward: 3.390. Training.\n",
            "[INFO] SnowballTarget. Step: 130000. Time Elapsed: 564.810 s. Mean Reward: 23.418. Std of Reward: 2.425. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 130000. Time Elapsed: 564.810 s. Mean Reward: 23.418. Std of Reward: 2.425. Training.\n",
            "[INFO] SnowballTarget. Step: 140000. Time Elapsed: 604.776 s. Mean Reward: 24.886. Std of Reward: 1.886. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 140000. Time Elapsed: 604.776 s. Mean Reward: 24.886. Std of Reward: 1.886. Training.\n",
            "[INFO] SnowballTarget. Step: 150000. Time Elapsed: 651.000 s. Mean Reward: 24.655. Std of Reward: 2.616. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 150000. Time Elapsed: 651.000 s. Mean Reward: 24.655. Std of Reward: 2.616. Training.\n",
            "[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-149984.onnx\n",
            "INFO:mlagents.trainers.torch_entities.model_serialization:Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-149984.onnx\n",
            "[INFO] SnowballTarget. Step: 160000. Time Elapsed: 691.785 s. Mean Reward: 24.909. Std of Reward: 2.076. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 160000. Time Elapsed: 691.785 s. Mean Reward: 24.909. Std of Reward: 2.076. Training.\n",
            "[INFO] SnowballTarget. Step: 170000. Time Elapsed: 736.045 s. Mean Reward: 24.727. Std of Reward: 2.195. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 170000. Time Elapsed: 736.045 s. Mean Reward: 24.727. Std of Reward: 2.195. Training.\n",
            "[INFO] SnowballTarget. Step: 180000. Time Elapsed: 778.759 s. Mean Reward: 24.932. Std of Reward: 2.189. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 180000. Time Elapsed: 778.759 s. Mean Reward: 24.932. Std of Reward: 2.189. Training.\n",
            "[INFO] SnowballTarget. Step: 190000. Time Elapsed: 823.119 s. Mean Reward: 25.400. Std of Reward: 2.409. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 190000. Time Elapsed: 823.119 s. Mean Reward: 25.400. Std of Reward: 2.409. Training.\n",
            "[INFO] SnowballTarget. Step: 200000. Time Elapsed: 863.327 s. Mean Reward: 25.205. Std of Reward: 1.914. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 200000. Time Elapsed: 863.327 s. Mean Reward: 25.205. Std of Reward: 1.914. Training.\n",
            "[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-199984.onnx\n",
            "INFO:mlagents.trainers.torch_entities.model_serialization:Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-199984.onnx\n",
            "[INFO] SnowballTarget. Step: 210000. Time Elapsed: 907.015 s. Mean Reward: 25.818. Std of Reward: 2.200. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 210000. Time Elapsed: 907.015 s. Mean Reward: 25.818. Std of Reward: 2.200. Training.\n",
            "[INFO] SnowballTarget. Step: 220000. Time Elapsed: 952.713 s. Mean Reward: 26.241. Std of Reward: 2.285. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 220000. Time Elapsed: 952.713 s. Mean Reward: 26.241. Std of Reward: 2.285. Training.\n",
            "[INFO] SnowballTarget. Step: 230000. Time Elapsed: 991.681 s. Mean Reward: 26.156. Std of Reward: 2.431. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 230000. Time Elapsed: 991.681 s. Mean Reward: 26.156. Std of Reward: 2.431. Training.\n",
            "[INFO] SnowballTarget. Step: 240000. Time Elapsed: 1037.501 s. Mean Reward: 26.036. Std of Reward: 2.248. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 240000. Time Elapsed: 1037.501 s. Mean Reward: 26.036. Std of Reward: 2.248. Training.\n",
            "[INFO] SnowballTarget. Step: 250000. Time Elapsed: 1075.878 s. Mean Reward: 25.864. Std of Reward: 2.380. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 250000. Time Elapsed: 1075.878 s. Mean Reward: 25.864. Std of Reward: 2.380. Training.\n",
            "[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-249944.onnx\n",
            "INFO:mlagents.trainers.torch_entities.model_serialization:Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-249944.onnx\n",
            "[INFO] SnowballTarget. Step: 260000. Time Elapsed: 1127.581 s. Mean Reward: 25.909. Std of Reward: 2.143. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 260000. Time Elapsed: 1127.581 s. Mean Reward: 25.909. Std of Reward: 2.143. Training.\n",
            "[INFO] SnowballTarget. Step: 270000. Time Elapsed: 1169.635 s. Mean Reward: 26.023. Std of Reward: 2.127. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 270000. Time Elapsed: 1169.635 s. Mean Reward: 26.023. Std of Reward: 2.127. Training.\n",
            "[INFO] SnowballTarget. Step: 280000. Time Elapsed: 1213.706 s. Mean Reward: 25.909. Std of Reward: 2.353. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 280000. Time Elapsed: 1213.706 s. Mean Reward: 25.909. Std of Reward: 2.353. Training.\n",
            "[INFO] SnowballTarget. Step: 290000. Time Elapsed: 1255.101 s. Mean Reward: 25.886. Std of Reward: 3.256. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 290000. Time Elapsed: 1255.101 s. Mean Reward: 25.886. Std of Reward: 3.256. Training.\n",
            "[INFO] SnowballTarget. Step: 300000. Time Elapsed: 1299.404 s. Mean Reward: 26.927. Std of Reward: 2.035. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 300000. Time Elapsed: 1299.404 s. Mean Reward: 26.927. Std of Reward: 2.035. Training.\n",
            "[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-299968.onnx\n",
            "INFO:mlagents.trainers.torch_entities.model_serialization:Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-299968.onnx\n",
            "[INFO] SnowballTarget. Step: 310000. Time Elapsed: 1340.850 s. Mean Reward: 26.886. Std of Reward: 2.298. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 310000. Time Elapsed: 1340.850 s. Mean Reward: 26.886. Std of Reward: 2.298. Training.\n",
            "[INFO] SnowballTarget. Step: 320000. Time Elapsed: 1385.923 s. Mean Reward: 26.564. Std of Reward: 1.837. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 320000. Time Elapsed: 1385.923 s. Mean Reward: 26.564. Std of Reward: 1.837. Training.\n",
            "[INFO] SnowballTarget. Step: 330000. Time Elapsed: 1430.360 s. Mean Reward: 25.630. Std of Reward: 2.102. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 330000. Time Elapsed: 1430.360 s. Mean Reward: 25.630. Std of Reward: 2.102. Training.\n",
            "[INFO] SnowballTarget. Step: 340000. Time Elapsed: 1471.089 s. Mean Reward: 26.222. Std of Reward: 2.200. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 340000. Time Elapsed: 1471.089 s. Mean Reward: 26.222. Std of Reward: 2.200. Training.\n",
            "[INFO] SnowballTarget. Step: 350000. Time Elapsed: 1515.539 s. Mean Reward: 26.455. Std of Reward: 2.147. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 350000. Time Elapsed: 1515.539 s. Mean Reward: 26.455. Std of Reward: 2.147. Training.\n",
            "[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-349992.onnx\n",
            "INFO:mlagents.trainers.torch_entities.model_serialization:Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-349992.onnx\n",
            "[INFO] SnowballTarget. Step: 360000. Time Elapsed: 1555.358 s. Mean Reward: 26.318. Std of Reward: 2.447. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 360000. Time Elapsed: 1555.358 s. Mean Reward: 26.318. Std of Reward: 2.447. Training.\n",
            "[INFO] SnowballTarget. Step: 370000. Time Elapsed: 1600.943 s. Mean Reward: 26.527. Std of Reward: 2.419. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 370000. Time Elapsed: 1600.943 s. Mean Reward: 26.527. Std of Reward: 2.419. Training.\n",
            "[INFO] SnowballTarget. Step: 380000. Time Elapsed: 1642.238 s. Mean Reward: 26.227. Std of Reward: 1.820. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 380000. Time Elapsed: 1642.238 s. Mean Reward: 26.227. Std of Reward: 1.820. Training.\n",
            "[INFO] SnowballTarget. Step: 390000. Time Elapsed: 1685.941 s. Mean Reward: 27.073. Std of Reward: 1.798. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 390000. Time Elapsed: 1685.941 s. Mean Reward: 27.073. Std of Reward: 1.798. Training.\n",
            "[INFO] SnowballTarget. Step: 400000. Time Elapsed: 1727.480 s. Mean Reward: 26.909. Std of Reward: 1.952. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 400000. Time Elapsed: 1727.480 s. Mean Reward: 26.909. Std of Reward: 1.952. Training.\n",
            "[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-399992.onnx\n",
            "INFO:mlagents.trainers.torch_entities.model_serialization:Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-399992.onnx\n",
            "[INFO] SnowballTarget. Step: 410000. Time Elapsed: 1778.190 s. Mean Reward: 26.836. Std of Reward: 2.477. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 410000. Time Elapsed: 1778.190 s. Mean Reward: 26.836. Std of Reward: 2.477. Training.\n",
            "[INFO] SnowballTarget. Step: 420000. Time Elapsed: 1818.341 s. Mean Reward: 27.432. Std of Reward: 2.270. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 420000. Time Elapsed: 1818.341 s. Mean Reward: 27.432. Std of Reward: 2.270. Training.\n",
            "[INFO] SnowballTarget. Step: 430000. Time Elapsed: 1863.212 s. Mean Reward: 27.582. Std of Reward: 1.745. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 430000. Time Elapsed: 1863.212 s. Mean Reward: 27.582. Std of Reward: 1.745. Training.\n",
            "[INFO] SnowballTarget. Step: 440000. Time Elapsed: 1909.396 s. Mean Reward: 27.574. Std of Reward: 2.087. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 440000. Time Elapsed: 1909.396 s. Mean Reward: 27.574. Std of Reward: 2.087. Training.\n",
            "[INFO] SnowballTarget. Step: 450000. Time Elapsed: 1949.466 s. Mean Reward: 27.467. Std of Reward: 2.050. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 450000. Time Elapsed: 1949.466 s. Mean Reward: 27.467. Std of Reward: 2.050. Training.\n",
            "[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-449952.onnx\n",
            "INFO:mlagents.trainers.torch_entities.model_serialization:Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-449952.onnx\n",
            "[INFO] SnowballTarget. Step: 460000. Time Elapsed: 1994.252 s. Mean Reward: 27.018. Std of Reward: 2.093. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 460000. Time Elapsed: 1994.252 s. Mean Reward: 27.018. Std of Reward: 2.093. Training.\n",
            "[INFO] SnowballTarget. Step: 470000. Time Elapsed: 2034.554 s. Mean Reward: 27.818. Std of Reward: 1.886. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 470000. Time Elapsed: 2034.554 s. Mean Reward: 27.818. Std of Reward: 1.886. Training.\n",
            "[INFO] SnowballTarget. Step: 480000. Time Elapsed: 2080.431 s. Mean Reward: 27.091. Std of Reward: 2.109. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 480000. Time Elapsed: 2080.431 s. Mean Reward: 27.091. Std of Reward: 2.109. Training.\n",
            "[INFO] SnowballTarget. Step: 490000. Time Elapsed: 2122.402 s. Mean Reward: 26.705. Std of Reward: 2.232. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 490000. Time Elapsed: 2122.402 s. Mean Reward: 26.705. Std of Reward: 2.232. Training.\n",
            "[INFO] SnowballTarget. Step: 500000. Time Elapsed: 2166.154 s. Mean Reward: 27.473. Std of Reward: 1.896. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 500000. Time Elapsed: 2166.154 s. Mean Reward: 27.473. Std of Reward: 1.896. Training.\n",
            "[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-499976.onnx\n",
            "INFO:mlagents.trainers.torch_entities.model_serialization:Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-499976.onnx\n",
            "[INFO] SnowballTarget. Step: 510000. Time Elapsed: 2208.212 s. Mean Reward: 27.159. Std of Reward: 1.718. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 510000. Time Elapsed: 2208.212 s. Mean Reward: 27.159. Std of Reward: 1.718. Training.\n",
            "[INFO] SnowballTarget. Step: 520000. Time Elapsed: 2254.040 s. Mean Reward: 26.982. Std of Reward: 2.170. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 520000. Time Elapsed: 2254.040 s. Mean Reward: 26.982. Std of Reward: 2.170. Training.\n",
            "[INFO] SnowballTarget. Step: 530000. Time Elapsed: 2295.574 s. Mean Reward: 27.250. Std of Reward: 1.639. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 530000. Time Elapsed: 2295.574 s. Mean Reward: 27.250. Std of Reward: 1.639. Training.\n",
            "[INFO] SnowballTarget. Step: 540000. Time Elapsed: 2340.904 s. Mean Reward: 27.255. Std of Reward: 1.890. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 540000. Time Elapsed: 2340.904 s. Mean Reward: 27.255. Std of Reward: 1.890. Training.\n",
            "[INFO] SnowballTarget. Step: 550000. Time Elapsed: 2388.013 s. Mean Reward: 27.204. Std of Reward: 1.909. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 550000. Time Elapsed: 2388.013 s. Mean Reward: 27.204. Std of Reward: 1.909. Training.\n",
            "[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-549992.onnx\n",
            "INFO:mlagents.trainers.torch_entities.model_serialization:Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-549992.onnx\n",
            "[INFO] SnowballTarget. Step: 560000. Time Elapsed: 2428.142 s. Mean Reward: 27.644. Std of Reward: 2.172. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 560000. Time Elapsed: 2428.142 s. Mean Reward: 27.644. Std of Reward: 2.172. Training.\n",
            "[INFO] SnowballTarget. Step: 570000. Time Elapsed: 2474.831 s. Mean Reward: 27.927. Std of Reward: 1.757. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 570000. Time Elapsed: 2474.831 s. Mean Reward: 27.927. Std of Reward: 1.757. Training.\n",
            "[INFO] SnowballTarget. Step: 580000. Time Elapsed: 2515.457 s. Mean Reward: 27.750. Std of Reward: 1.653. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 580000. Time Elapsed: 2515.457 s. Mean Reward: 27.750. Std of Reward: 1.653. Training.\n",
            "[INFO] SnowballTarget. Step: 590000. Time Elapsed: 2561.117 s. Mean Reward: 27.255. Std of Reward: 1.956. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 590000. Time Elapsed: 2561.117 s. Mean Reward: 27.255. Std of Reward: 1.956. Training.\n",
            "[INFO] SnowballTarget. Step: 600000. Time Elapsed: 2603.116 s. Mean Reward: 27.841. Std of Reward: 2.266. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 600000. Time Elapsed: 2603.116 s. Mean Reward: 27.841. Std of Reward: 2.266. Training.\n",
            "[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-599936.onnx\n",
            "INFO:mlagents.trainers.torch_entities.model_serialization:Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-599936.onnx\n",
            "[INFO] SnowballTarget. Step: 610000. Time Elapsed: 2647.399 s. Mean Reward: 27.782. Std of Reward: 2.069. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 610000. Time Elapsed: 2647.399 s. Mean Reward: 27.782. Std of Reward: 2.069. Training.\n",
            "[INFO] SnowballTarget. Step: 620000. Time Elapsed: 2689.153 s. Mean Reward: 28.205. Std of Reward: 1.727. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 620000. Time Elapsed: 2689.153 s. Mean Reward: 28.205. Std of Reward: 1.727. Training.\n",
            "[INFO] SnowballTarget. Step: 630000. Time Elapsed: 2734.199 s. Mean Reward: 27.491. Std of Reward: 1.639. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 630000. Time Elapsed: 2734.199 s. Mean Reward: 27.491. Std of Reward: 1.639. Training.\n",
            "[INFO] SnowballTarget. Step: 640000. Time Elapsed: 2774.487 s. Mean Reward: 27.591. Std of Reward: 1.800. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 640000. Time Elapsed: 2774.487 s. Mean Reward: 27.591. Std of Reward: 1.800. Training.\n",
            "[INFO] SnowballTarget. Step: 650000. Time Elapsed: 2819.292 s. Mean Reward: 27.727. Std of Reward: 1.882. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 650000. Time Elapsed: 2819.292 s. Mean Reward: 27.727. Std of Reward: 1.882. Training.\n",
            "[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-649960.onnx\n",
            "INFO:mlagents.trainers.torch_entities.model_serialization:Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-649960.onnx\n",
            "[INFO] SnowballTarget. Step: 660000. Time Elapsed: 2864.219 s. Mean Reward: 27.370. Std of Reward: 2.247. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 660000. Time Elapsed: 2864.219 s. Mean Reward: 27.370. Std of Reward: 2.247. Training.\n",
            "[INFO] SnowballTarget. Step: 670000. Time Elapsed: 2904.536 s. Mean Reward: 28.511. Std of Reward: 1.985. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 670000. Time Elapsed: 2904.536 s. Mean Reward: 28.511. Std of Reward: 1.985. Training.\n",
            "[INFO] SnowballTarget. Step: 680000. Time Elapsed: 2949.484 s. Mean Reward: 27.745. Std of Reward: 2.011. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 680000. Time Elapsed: 2949.484 s. Mean Reward: 27.745. Std of Reward: 2.011. Training.\n",
            "[INFO] SnowballTarget. Step: 690000. Time Elapsed: 2989.870 s. Mean Reward: 27.273. Std of Reward: 1.875. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 690000. Time Elapsed: 2989.870 s. Mean Reward: 27.273. Std of Reward: 1.875. Training.\n",
            "[INFO] SnowballTarget. Step: 700000. Time Elapsed: 3036.717 s. Mean Reward: 27.818. Std of Reward: 1.898. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 700000. Time Elapsed: 3036.717 s. Mean Reward: 27.818. Std of Reward: 1.898. Training.\n",
            "[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-699984.onnx\n",
            "INFO:mlagents.trainers.torch_entities.model_serialization:Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-699984.onnx\n",
            "[INFO] SnowballTarget. Step: 710000. Time Elapsed: 3078.482 s. Mean Reward: 27.545. Std of Reward: 1.815. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 710000. Time Elapsed: 3078.482 s. Mean Reward: 27.545. Std of Reward: 1.815. Training.\n",
            "[INFO] SnowballTarget. Step: 720000. Time Elapsed: 3123.058 s. Mean Reward: 27.800. Std of Reward: 2.075. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 720000. Time Elapsed: 3123.058 s. Mean Reward: 27.800. Std of Reward: 2.075. Training.\n",
            "[INFO] SnowballTarget. Step: 730000. Time Elapsed: 3164.883 s. Mean Reward: 27.705. Std of Reward: 2.760. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 730000. Time Elapsed: 3164.883 s. Mean Reward: 27.705. Std of Reward: 2.760. Training.\n",
            "[INFO] SnowballTarget. Step: 740000. Time Elapsed: 3210.316 s. Mean Reward: 28.018. Std of Reward: 1.931. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 740000. Time Elapsed: 3210.316 s. Mean Reward: 28.018. Std of Reward: 1.931. Training.\n",
            "[INFO] SnowballTarget. Step: 750000. Time Elapsed: 3251.557 s. Mean Reward: 27.864. Std of Reward: 2.262. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 750000. Time Elapsed: 3251.557 s. Mean Reward: 27.864. Std of Reward: 2.262. Training.\n",
            "[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-749984.onnx\n",
            "INFO:mlagents.trainers.torch_entities.model_serialization:Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-749984.onnx\n",
            "[INFO] SnowballTarget. Step: 760000. Time Elapsed: 3297.107 s. Mean Reward: 28.000. Std of Reward: 1.945. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 760000. Time Elapsed: 3297.107 s. Mean Reward: 28.000. Std of Reward: 1.945. Training.\n",
            "[INFO] SnowballTarget. Step: 770000. Time Elapsed: 3342.288 s. Mean Reward: 27.907. Std of Reward: 2.271. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 770000. Time Elapsed: 3342.288 s. Mean Reward: 27.907. Std of Reward: 2.271. Training.\n",
            "[INFO] SnowballTarget. Step: 780000. Time Elapsed: 3382.847 s. Mean Reward: 27.733. Std of Reward: 1.718. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 780000. Time Elapsed: 3382.847 s. Mean Reward: 27.733. Std of Reward: 1.718. Training.\n",
            "[INFO] SnowballTarget. Step: 790000. Time Elapsed: 3428.479 s. Mean Reward: 27.836. Std of Reward: 2.078. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 790000. Time Elapsed: 3428.479 s. Mean Reward: 27.836. Std of Reward: 2.078. Training.\n",
            "[INFO] SnowballTarget. Step: 800000. Time Elapsed: 3468.965 s. Mean Reward: 28.023. Std of Reward: 2.028. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 800000. Time Elapsed: 3468.965 s. Mean Reward: 28.023. Std of Reward: 2.028. Training.\n",
            "[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-799944.onnx\n",
            "INFO:mlagents.trainers.torch_entities.model_serialization:Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-799944.onnx\n",
            "[INFO] SnowballTarget. Step: 810000. Time Elapsed: 3513.018 s. Mean Reward: 28.364. Std of Reward: 2.066. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 810000. Time Elapsed: 3513.018 s. Mean Reward: 28.364. Std of Reward: 2.066. Training.\n",
            "[INFO] SnowballTarget. Step: 820000. Time Elapsed: 3554.885 s. Mean Reward: 28.409. Std of Reward: 1.788. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 820000. Time Elapsed: 3554.885 s. Mean Reward: 28.409. Std of Reward: 1.788. Training.\n",
            "[INFO] SnowballTarget. Step: 830000. Time Elapsed: 3599.076 s. Mean Reward: 28.127. Std of Reward: 2.072. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 830000. Time Elapsed: 3599.076 s. Mean Reward: 28.127. Std of Reward: 2.072. Training.\n",
            "[INFO] SnowballTarget. Step: 840000. Time Elapsed: 3639.707 s. Mean Reward: 28.682. Std of Reward: 2.065. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 840000. Time Elapsed: 3639.707 s. Mean Reward: 28.682. Std of Reward: 2.065. Training.\n",
            "[INFO] SnowballTarget. Step: 850000. Time Elapsed: 3686.241 s. Mean Reward: 28.309. Std of Reward: 2.131. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 850000. Time Elapsed: 3686.241 s. Mean Reward: 28.309. Std of Reward: 2.131. Training.\n",
            "[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-849968.onnx\n",
            "INFO:mlagents.trainers.torch_entities.model_serialization:Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-849968.onnx\n",
            "[INFO] SnowballTarget. Step: 860000. Time Elapsed: 3726.347 s. Mean Reward: 28.250. Std of Reward: 1.932. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 860000. Time Elapsed: 3726.347 s. Mean Reward: 28.250. Std of Reward: 1.932. Training.\n",
            "[INFO] SnowballTarget. Step: 870000. Time Elapsed: 3772.178 s. Mean Reward: 28.418. Std of Reward: 1.970. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 870000. Time Elapsed: 3772.178 s. Mean Reward: 28.418. Std of Reward: 1.970. Training.\n",
            "[INFO] SnowballTarget. Step: 880000. Time Elapsed: 3817.876 s. Mean Reward: 28.685. Std of Reward: 2.176. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 880000. Time Elapsed: 3817.876 s. Mean Reward: 28.685. Std of Reward: 2.176. Training.\n",
            "[INFO] SnowballTarget. Step: 890000. Time Elapsed: 3858.686 s. Mean Reward: 27.733. Std of Reward: 1.879. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 890000. Time Elapsed: 3858.686 s. Mean Reward: 27.733. Std of Reward: 1.879. Training.\n",
            "[INFO] SnowballTarget. Step: 900000. Time Elapsed: 3904.517 s. Mean Reward: 28.291. Std of Reward: 2.946. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 900000. Time Elapsed: 3904.517 s. Mean Reward: 28.291. Std of Reward: 2.946. Training.\n",
            "[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-899992.onnx\n",
            "INFO:mlagents.trainers.torch_entities.model_serialization:Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-899992.onnx\n",
            "[INFO] SnowballTarget. Step: 910000. Time Elapsed: 3944.938 s. Mean Reward: 28.614. Std of Reward: 1.921. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 910000. Time Elapsed: 3944.938 s. Mean Reward: 28.614. Std of Reward: 1.921. Training.\n",
            "[INFO] SnowballTarget. Step: 920000. Time Elapsed: 3990.105 s. Mean Reward: 27.927. Std of Reward: 1.704. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 920000. Time Elapsed: 3990.105 s. Mean Reward: 27.927. Std of Reward: 1.704. Training.\n",
            "[INFO] SnowballTarget. Step: 930000. Time Elapsed: 4032.307 s. Mean Reward: 28.091. Std of Reward: 1.743. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 930000. Time Elapsed: 4032.307 s. Mean Reward: 28.091. Std of Reward: 1.743. Training.\n",
            "[INFO] SnowballTarget. Step: 940000. Time Elapsed: 4075.260 s. Mean Reward: 28.673. Std of Reward: 1.945. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 940000. Time Elapsed: 4075.260 s. Mean Reward: 28.673. Std of Reward: 1.945. Training.\n",
            "[INFO] SnowballTarget. Step: 950000. Time Elapsed: 4118.085 s. Mean Reward: 28.273. Std of Reward: 2.104. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 950000. Time Elapsed: 4118.085 s. Mean Reward: 28.273. Std of Reward: 2.104. Training.\n",
            "[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-949992.onnx\n",
            "INFO:mlagents.trainers.torch_entities.model_serialization:Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-949992.onnx\n",
            "[INFO] SnowballTarget. Step: 960000. Time Elapsed: 4163.382 s. Mean Reward: 27.709. Std of Reward: 2.262. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 960000. Time Elapsed: 4163.382 s. Mean Reward: 27.709. Std of Reward: 2.262. Training.\n",
            "[INFO] SnowballTarget. Step: 970000. Time Elapsed: 4201.688 s. Mean Reward: 28.182. Std of Reward: 1.825. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 970000. Time Elapsed: 4201.688 s. Mean Reward: 28.182. Std of Reward: 1.825. Training.\n",
            "[INFO] SnowballTarget. Step: 980000. Time Elapsed: 4247.070 s. Mean Reward: 28.236. Std of Reward: 2.381. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 980000. Time Elapsed: 4247.070 s. Mean Reward: 28.236. Std of Reward: 2.381. Training.\n",
            "[INFO] SnowballTarget. Step: 990000. Time Elapsed: 4292.955 s. Mean Reward: 27.759. Std of Reward: 2.236. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 990000. Time Elapsed: 4292.955 s. Mean Reward: 27.759. Std of Reward: 2.236. Training.\n",
            "[INFO] SnowballTarget. Step: 1000000. Time Elapsed: 4331.898 s. Mean Reward: 28.578. Std of Reward: 2.408. Training.\n",
            "INFO:mlagents.trainers.stats:SnowballTarget. Step: 1000000. Time Elapsed: 4331.898 s. Mean Reward: 28.578. Std of Reward: 2.408. Training.\n",
            "[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-999952.onnx\n",
            "INFO:mlagents.trainers.torch_entities.model_serialization:Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-999952.onnx\n",
            "[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-1000208.onnx\n",
            "INFO:mlagents.trainers.torch_entities.model_serialization:Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-1000208.onnx\n",
            "[INFO] Copied results/SnowballTarget1/SnowballTarget/SnowballTarget-1000208.onnx to results/SnowballTarget1/SnowballTarget.onnx.\n",
            "INFO:mlagents.trainers.model_saver.torch_model_saver:Copied results/SnowballTarget1/SnowballTarget/SnowballTarget-1000208.onnx to results/SnowballTarget1/SnowballTarget.onnx.\n"
          ]
        }
      ],
      "source": [
        "!mlagents-learn ./config/ppo/SnowballTarget.yaml --env=./training-envs-executables/linux/SnowballTarget/SnowballTarget --run-id=\"SnowballTarget1\" --no-graphics --force"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Vue94AzPy1t"
      },
      "source": [
        "### Push the agent to the ü§ó Hub\n",
        "\n",
        "- Now that we trained our agent, we‚Äôre **ready to push it to the Hub to be able to visualize it playing on your browserüî•.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izT6FpgNzZ6R"
      },
      "source": [
        "To be able to share your model with the community there are three more steps to follow:\n",
        "\n",
        "1Ô∏è‚É£ (If it's not already done) create an account to HF ‚û° https://huggingface.co/join\n",
        "\n",
        "2Ô∏è‚É£ Sign in and then, you need to store your authentication token from the Hugging Face website.\n",
        "- Create a new token (https://huggingface.co/settings/tokens) **with write role**\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/create-token.jpg\" alt=\"Create HF Token\">\n",
        "\n",
        "- Copy the token\n",
        "- Run the cell below and paste the token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rKt2vsYoK56o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160,
          "referenced_widgets": [
            "62f519e8272047bb8e49db3dd72f5f2e",
            "82a2a25521b345e5aa486c5d2ef6d745",
            "52d68334d023472eab29b547c42a18aa",
            "196dc2e8597f4a7faf021fe810afb55c",
            "03416377f667417b88848134a3023c91",
            "6444a8c6043c4063a8cc9cf60d2531b9",
            "7c9dde65cef54d2e9cb70050ebe18667",
            "299a149071a247eda185cc9cd3b6e116",
            "21ffa32a2ecd48c59ad292a0fa94d734",
            "9e6c43e987594906986d6833298ff6cc",
            "0ef680020ac24a8db995071f746b4f12",
            "219de625c73d45debc316f97c8832022",
            "e00504d9730a40dd9eecea5bfc965774",
            "c388b55f5ad34d1b900fcc24f63c45fd",
            "7d6329924321458e81106454a1475812",
            "3e9823b18d524d3baed640df8a161b97",
            "9269a0159ba7449a8575ef27d5e02e92",
            "32f52c52b4ea49bb884ffc188dc095e2",
            "a6d9e6b7ecc244d9b7f04e1ac1127446",
            "8f75a35d0921409b81f8e6a2fc217d32",
            "6e3a523c772649e0b4d883d2b8205cd9",
            "938b25a55b9641c3a10977f0493f0c05",
            "cacb6da400e244afb5993cbad9a72cde",
            "0df8266a32d346dcb02d701295f8320a",
            "3095c99248c3424ab51f7e0c21e85124",
            "6e32afbc49d34336b2c68e31074ef0c7",
            "645043d32a774126ae48fe871286d047",
            "57b27caad64d40859fbadf156112c315",
            "dd891ed6dc5c4163a01546e924b5ce8a",
            "56faf8ceb036490aaec12a84d64138f2",
            "e736551157a4415baafd60f3d98f0b4f",
            "eb28509222c34dc183d09586819fd9e6"
          ]
        },
        "outputId": "ea835f7c-a30f-42f9-9b6f-1200d8643524"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62f519e8272047bb8e49db3dd72f5f2e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSU9qD9_6dem"
      },
      "source": [
        "If you don't want to use a Google Colab or a Jupyter Notebook, you need to use this command instead: `huggingface-cli login`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KK4fPfnczunT"
      },
      "source": [
        "Then, we simply need to run `mlagents-push-to-hf`.\n",
        "\n",
        "And we define 4 parameters:\n",
        "\n",
        "1. `--run-id`: the name of the training run id.\n",
        "2. `--local-dir`: where the agent was saved, it‚Äôs results/<run_id name>, so in my case results/First Training.\n",
        "3. `--repo-id`: the name of the Hugging Face repo you want to create or update. It‚Äôs always <your huggingface username>/<the repo name>\n",
        "If the repo does not exist **it will be created automatically**\n",
        "4. `--commit-message`: since HF repos are git repository you need to define a commit message.\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/mlagentspushtohub.png\" alt=\"Push to Hub\"/>\n",
        "\n",
        "For instance:\n",
        "\n",
        "`!mlagents-push-to-hf  --run-id=\"SnowballTarget1\" --local-dir=\"./results/SnowballTarget1\" --repo-id=\"ThomasSimonini/ppo-SnowballTarget\"  --commit-message=\"First Push\"`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kAFzVB7OYj_H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83202fc3-b9e6-47c5-ee91-ef908154e882"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] This function will create a model card and upload your SnowballTarget1 into HuggingFace Hub. This is a work in progress: If you encounter a bug, please send open an issue\n",
            "[INFO] Pushing repo SnowballTarget1 to the Hugging Face Hub\n",
            "SnowballTarget-1000208.pt:   0% 0.00/7.02M [00:00<?, ?B/s]\n",
            "SnowballTarget-599936.onnx:   0% 0.00/1.18M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "SnowballTarget.onnx:   0% 0.00/1.18M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "SnowballTarget-649960.onnx:   0% 0.00/1.18M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Upload 23 LFS files:   0% 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "SnowballTarget-599936.pt:   0% 0.00/7.02M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "SnowballTarget.onnx:   1% 16.4k/1.18M [00:00<00:42, 27.4kB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "SnowballTarget-1000208.pt:   0% 16.4k/7.02M [00:00<04:25, 26.3kB/s]\n",
            "\n",
            "\n",
            "SnowballTarget-649960.onnx:   1% 16.4k/1.18M [00:00<00:43, 26.4kB/s]\u001b[A\u001b[A\u001b[A\n",
            "SnowballTarget-599936.onnx:   1% 16.4k/1.18M [00:00<00:44, 26.0kB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "SnowballTarget.onnx: 100% 1.18M/1.18M [00:00<00:00, 1.36MB/s]\n",
            "SnowballTarget-599936.onnx: 100% 1.18M/1.18M [00:00<00:00, 1.32MB/s]\n",
            "SnowballTarget-649960.onnx: 100% 1.18M/1.18M [00:00<00:00, 1.28MB/s]\n",
            "SnowballTarget-1000208.pt: 100% 7.02M/7.02M [00:00<00:00, 7.13MB/s]\n",
            "SnowballTarget-599936.pt: 100% 7.02M/7.02M [00:00<00:00, 7.13MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "SnowballTarget-649960.pt:  99% 6.96M/7.02M [00:00<00:00, 65.7MB/s]\n",
            "SnowballTarget-699984.onnx:   0% 0.00/1.18M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "SnowballTarget-699984.pt:   0% 0.00/7.02M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "SnowballTarget-749984.onnx:   0% 0.00/1.18M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Upload 23 LFS files:   9% 2/23 [00:01<00:15,  1.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "SnowballTarget-649960.pt: 100% 7.02M/7.02M [00:00<00:00, 20.8MB/s]\n",
            "SnowballTarget-799944.onnx:   0% 0.00/1.18M [00:00<?, ?B/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "SnowballTarget-699984.onnx: 100% 1.18M/1.18M [00:00<00:00, 4.90MB/s]\n",
            "SnowballTarget-749984.onnx: 100% 1.18M/1.18M [00:00<00:00, 5.04MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload 23 LFS files:  30% 7/23 [00:01<00:02,  5.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "SnowballTarget-799944.onnx: 100% 1.18M/1.18M [00:00<00:00, 7.03MB/s]\n",
            "SnowballTarget-699984.pt: 100% 7.02M/7.02M [00:00<00:00, 22.5MB/s]\n",
            "SnowballTarget-849968.onnx:   0% 0.00/1.18M [00:00<?, ?B/s]\n",
            "SnowballTarget-799944.pt:  93% 6.55M/7.02M [00:00<00:00, 63.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Upload 23 LFS files:  39% 9/23 [00:01<00:01,  7.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "SnowballTarget-849968.pt:   0% 0.00/7.02M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "SnowballTarget-749984.pt: 100% 7.02M/7.02M [00:00<00:00, 15.5MB/s]\n",
            "\n",
            "\n",
            "SnowballTarget-849968.pt:  99% 6.95M/7.02M [00:00<00:00, 69.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Upload 23 LFS files:  48% 11/23 [00:02<00:01,  8.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "SnowballTarget-849968.onnx: 100% 1.18M/1.18M [00:00<00:00, 4.46MB/s]\n",
            "SnowballTarget-899992.onnx: 100% 1.18M/1.18M [00:00<00:00, 5.78MB/s]\n",
            "SnowballTarget-799944.pt: 100% 7.02M/7.02M [00:00<00:00, 19.3MB/s]\n",
            "SnowballTarget-949992.onnx:   0% 0.00/1.18M [00:00<?, ?B/s]\n",
            "SnowballTarget-949992.pt:   0% 0.00/7.02M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Upload 23 LFS files:  57% 13/23 [00:02<00:01,  8.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "SnowballTarget-849968.pt: 100% 7.02M/7.02M [00:00<00:00, 16.7MB/s]\n",
            "SnowballTarget-949992.onnx: 100% 1.18M/1.18M [00:00<00:00, 6.56MB/s]\n",
            "SnowballTarget-999952.pt:   0% 0.00/7.02M [00:00<?, ?B/s]\n",
            "\n",
            "\n",
            "\n",
            "Upload 23 LFS files:  65% 15/23 [00:02<00:00,  9.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "SnowballTarget-899992.pt: 100% 7.02M/7.02M [00:00<00:00, 18.7MB/s]\n",
            "SnowballTarget.onnx: 100% 1.18M/1.18M [00:00<00:00, 4.32MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload 23 LFS files:  74% 17/23 [00:02<00:00, 10.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "SnowballTarget-949992.pt: 100% 7.02M/7.02M [00:00<00:00, 22.6MB/s]\n",
            "\n",
            "SnowballTarget-999952.pt: 100% 7.02M/7.02M [00:00<00:00, 21.6MB/s]\n",
            "events.out.tfevents.1705752665.80e242070a31.7250.0: 100% 94.3k/94.3k [00:00<00:00, 511kB/s]\n",
            "checkpoint.pt: 100% 7.02M/7.02M [00:00<00:00, 20.9MB/s]\n",
            "SnowballTarget.onnx: 100% 1.18M/1.18M [00:00<00:00, 5.88MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload 23 LFS files: 100% 23/23 [00:02<00:00,  7.72it/s]\n",
            "[INFO] Your model is pushed to the hub. You can view your model here: https://huggingface.co/k0T0z/ppo-SnowballTarget\n"
          ]
        }
      ],
      "source": [
        "!mlagents-push-to-hf --run-id=\"SnowballTarget1\" --local-dir=\"./results/SnowballTarget1\" --repo-id=\"k0T0z/ppo-SnowballTarget\" --commit-message=\"First Push\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGEFAIboLVc6"
      },
      "outputs": [],
      "source": [
        "!mlagents-push-to-hf  --run-id= # Add your run id  --local-dir= # Your local dir  --repo-id= # Your repo id  --commit-message= # Your commit message"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yborB0850FTM"
      },
      "source": [
        "Else, if everything worked you should have this at the end of the process(but with a different url üòÜ) :\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Your model is pushed to the hub. You can view your model here: https://huggingface.co/ThomasSimonini/ppo-SnowballTarget\n",
        "```\n",
        "\n",
        "It‚Äôs the link to your model, it contains a model card that explains how to use it, your Tensorboard and your config file. **What‚Äôs awesome is that it‚Äôs a git repository, that means you can have different commits, update your repository with a new push etc.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Uaon2cg0NrL"
      },
      "source": [
        "But now comes the best: **being able to visualize your agent online üëÄ.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMc4oOsE0QiZ"
      },
      "source": [
        "### Watch your agent playing üëÄ\n",
        "\n",
        "For this step it‚Äôs simple:\n",
        "\n",
        "1. Remember your repo-id\n",
        "\n",
        "2. Go here: https://huggingface.co/spaces/ThomasSimonini/ML-Agents-SnowballTarget\n",
        "\n",
        "3. Launch the game and put it in full screen by clicking on the bottom right button\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/snowballtarget_load.png\" alt=\"Snowballtarget load\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Djs8c5rR0Z8a"
      },
      "source": [
        "1. In step 1, choose your model repository which is the model id (in my case ThomasSimonini/ppo-SnowballTarget).\n",
        "\n",
        "2. In step 2, **choose what model you want to replay**:\n",
        "  - I have multiple one, since we saved a model every 500000 timesteps.\n",
        "  - But if I want the more recent I choose `SnowballTarget.onnx`\n",
        "\n",
        "üëâ What‚Äôs nice **is to try with different models step to see the improvement of the agent.**\n",
        "\n",
        "And don't hesitate to share the best score your agent gets on discord in #rl-i-made-this channel üî•\n",
        "\n",
        "Let's now try a harder environment called Pyramids..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVMwRi4y_tmx"
      },
      "source": [
        "## Pyramids üèÜ\n",
        "\n",
        "### Download and move the environment zip file in `./training-envs-executables/linux/`\n",
        "- Our environment executable is in a zip file.\n",
        "- We need to download it and place it to `./training-envs-executables/linux/`\n",
        "- We use a linux executable because we use colab, and colab machines OS is Ubuntu (linux)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyqYYkLyAVMK"
      },
      "source": [
        "Download the file Pyramids.zip from https://drive.google.com/uc?export=download&id=1UiFNdKlsH0NTu32xV-giYUEVKV4-vc7H using `wget`. Check out the full solution to download large files from GDrive [here](https://bcrf.biochem.wisc.edu/2021/02/05/download-google-drive-files-using-wget/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxojCsSVAVMP"
      },
      "outputs": [],
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1UiFNdKlsH0NTu32xV-giYUEVKV4-vc7H' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1UiFNdKlsH0NTu32xV-giYUEVKV4-vc7H\" -O ./training-envs-executables/linux/Pyramids.zip && rm -rf /tmp/cookies.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfs6CTJ1AVMP"
      },
      "source": [
        "**OR** Download directly to local machine and then drag and drop the file from local machine to `./training-envs-executables/linux`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7JmgOwcSSmF"
      },
      "source": [
        "Wait for the upload to finish and then run the command below.\n",
        "\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAASYAAAAfCAYAAABKxmALAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAmZSURBVHhe7d0NTNTnHQfwL+rxcigHFHUH9LCCVuaKCWgB4029Gq7NcBuLPdPKEhh6iRhEmauLY2V0ptEUSZGwTJTA5jSBOnGDmpyxEMUqxEH0rOIQfDmtt/oCnsof9BT2PPAcx8nbeTQi9vcxF56X+///h8n98vs9/xfcYmJiukEIIS+RCeInIYS8NChjIoS4LCwsDMHBwfDx8cEc76u4dNcT5y63orm5WbzDNRSYCCHPhQejuLg4xMbGwtvbW4wCymNLRAuQFAtwpW0Sio+34+uzN8So8ygwEUKc4uXlheTkZCxbtkyMOOofmGy63P1R37EAm4u+QUdHhxgdGa0xEUJGxLOknJycQYPSvXv3cPnyZTx0n4Fut4litNeEx61YMNGAQxun9uzDWZQxEUKGxQNKVlaWQ9nGg9Hhw4dx8uRJ3Lx5U4wCQYouvD3bB+qfTEWsT70Ytfv1l287tf5EgYkQMiRevvFMSalUihHAYDCgpKQEjx49EiODWzwL+MN73Zji1iZGgO/8l+ODbQ0jlnXjtJQLheZ9HTQzRXcAHbKK8pEeK7rfi5GOScirh68p9Q9K+/fvx65du0YMStyxS0DcTjecuh8lRoDprRXY8pvFoje0IQJTNNLzilBU5PjK35qO+Dly8Z6xFAF1nBZaTbjovwhjcUxCxg4v4fqvKfFM6cCBA6LnvIziK7jdFSh6wBKfE4iaGyJ6gxs2Y5LOFiIlJYW90pC5rQT1CEfCulRoxzw2lSN7TQo272kU/RdhLI5JyNjhlwTY8DUlXr65avMBq2gBkyQTUjUeoje4IdaYeMakR1hLIdJ21okxJigJ2z+JgeVQBpoj86GVVSEzcx/M/ecqMvCVajv0Ac1okEcg0s8EQ0o2KiNX4XeJaqgUMqDLCkuLAQXbytHCt41NR/7qqWhmhwpboISchUvJXIeyf9yGWh+PUAV7T5cFLV8W4NNDfAteqmmBIynILuU7CEXC79chfhZ7Y5cE87lrkM0Lwc09acg7xablaui36BCt7I2okrkB5TsKUGUvfXutzEJRnEp07Ew9x3E8ZvT6/J7fsW5CWO9+2XFNJ4rx2d8aIIntCBnP9u7d27fgzUs4V7Kl/nKT3+hbEO+Y8hY0W7/taQ/GxTUmCZUXTYAyDGqRPckXhSDAakLjEfG1DAqHsqkMBTuKYUA8Nug1UJjKkJmWgrQdNbDMiEdyor12ZTtDiKIWxR9nILOYfbmV0Uj6rRqPq/OQsSkbZedZ+Hl3JdvTQBF6PeJnSKgpzkTGx8Wo9QhEgJjj4tevQrS8Gfsy05DGAmmzPBK61AQMSPxKs0WGyF+ZMFxlUd5iRFWFmH9WUAh86oqRuSkTJSctUP40GalLxRwh4xgv4/qfheNn30ar5pvbogV4Si3DXj7gfGDyi0D8h1Es+JjR3MBCU4URLVYVwpfzr7cc2jAlrNcbYbClC7dqUVBoQMMFEyzyepTu/BSfFVbBzOali/vQyNIs5Rtq8WbOjPqCSjSYLTCzzMPIg6m5Hn9hx7G0sayr7hokmRKhAxa0o7F0bgAsZ8tQcsIMC8uGKgvqe7M4Qe4hg9V8EbXs4JK5CmUHK1Fz8Q54IjYU5ft6aFiwMx7cjZqhUqBv+edrgLnNzIJiGc61yRE2n2VVhIxz/DYTG17G9b8kwFXHL9wXLVaqPZUQPWuy6A00bGCSz9PbF79z0pGgsqCh9HOU8aAhGdB43cqSJi0LSxqEv85KnvMGexnTyUoq0WTRAHemxEC/9a99+9Pyisnh6FZY+zaWYH3Kfjy1OlEWhcB3shV3bhhFn5HYvkSTq2lohHW2Dvm5W7GFZU8Rlirs+2eNQ/ByEKSD/h0VpLPl2H1imE/g8PmMMN6QIJMPF+4IGR/4vW82ra2tojU6d9snoHPSNNFjFZB/p2gNNGxgsi9+i1daJgqqLbZZGM6zcu71cGji5kCFfmXcs9gXfUMyL+XKkb2pd18GtumLYq7IQdpHeSg7ZcLjaVHQbdiO7aujxeyzQqFbrYFKMqJ8T40TgdFOLpOJFiFkMN39Qk433ERrIOdLuUFIh4wsHKmgficE6F/GPUulRIDMhNrPDTD1LDjLIXO8cn0UruHeQxkCgiNEn5HLYA8REdB+uAraYCMMXxQiJzMDef+REPBWDCsCBwpdmQiNSkLDF3lDl3CDUkLpz0pGyRa4CRm/7t+3l13+/v6iNTp+8i54Pfmf6AHNrZ6iNdCoAhNQCeN1ICBADnNzvzLuWZYONqdE1Go1VDNYIEveAnWQmBu1OlSfvwPFPB2SFimhUEZCtzGGHc0uZJ4GCSuTEO3HOn4RiORn0To7wP/r5ZEJSErUsDyJmalD4lJWwjWUooCfzRuJKgablkdAwf5FJOoRM01C4wmDmCRk/Lpxw/5EAF9fXwQG2q9DctWicPsyR/ckb5y+9ED0BhplYGKhiZdzvIyrGCa9uFCIwgoTZNFJyPpjFnSht3GOn/HylDsEEFcZCwtReVXOAt5W5H6SjIgH13BHzPG1n8JdZWhEFPQ5vWtlUR7NqNxVyMZY0IqMgXqxmuVVzIJwqFiqpYjst7bGXvnrhyj7bt2ENXoNcotykb44AOavirHbmYBGyEuO38/W3t4uesDChQtFy3VLIuznyjvks4e9Z27U98r1XM/jV4O07LLnWo8Z72y/dwr7vQl5FaWmpvZd+c3PzK1du9apW1EGMz/EDfm/vCt6LFfpikFKfpPoDeRyxiRXhiJ8/iq8+2MZWs5W/qCCEiE/BEeOHBGt3nIuKSlJ9J7fn39hX+jukilQMsICrsuBac6v1mHTWg0CrhpQeojCEiGvGl5qHT16VPQArVaLFStWiJ7z8lOC4etmX1w50zkfNWeGf6olPfaEEDKk0Tz2JCRgEnI/8EbghCtiBHjo9SZ+nvdwxMeeTAwODv6TaBNCiIMnT56gqampZ/Hb3d29Z8z21AGZTNaz9vTggf3s2mSPbqjn+kH/Xgg2xH4HRbf98oAnMn+sORiIW7duiZGhUcZECBkRD0YbN250yJxseHDiV4er7v8LP5K+hsxqL9tszK+twEd/Nzn911MoYyKEjIgHnurqaigUCsyc6fi0RE9PT/j5+UHx6L/wanW82bfL/TUcf/wzrN95yqlMyYYCEyHEKbysO336NOrr6+Hm5obp06f3lXech+UM3O+dwVOPqZB8ImFsfxMFx4A9/zb2bPs8qJQjhLiMl3i2P3ip9j2DpjZv1F7qxLmL9gVvV1BgIoS8dEZ9SwohhHzfKDARQl4ywP8B/eN9dc0U7ocAAAAASUVORK5CYII=)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWUUcs0_794U"
      },
      "source": [
        "Unzip it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "i2E3K4V2AVMP"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!unzip -d ./training-envs-executables/linux/ ./training-envs-executables/linux/Pyramids.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmKYBgHTAVMP"
      },
      "source": [
        "Make sure your file is accessible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Im-nwvLPAVMP"
      },
      "outputs": [],
      "source": [
        "!chmod -R 755 ./training-envs-executables/linux/Pyramids/Pyramids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqceIATXAgih"
      },
      "source": [
        "###  Modify the PyramidsRND config file\n",
        "- Contrary to the first environment which was a custom one, **Pyramids was made by the Unity team**.\n",
        "- So the PyramidsRND config file already exists and is in ./content/ml-agents/config/ppo/PyramidsRND.yaml\n",
        "- You might asked why \"RND\" in PyramidsRND. RND stands for *random network distillation* it's a way to generate curiosity rewards. If you want to know more on that we wrote an article explaning this technique: https://medium.com/data-from-the-trenches/curiosity-driven-learning-through-random-network-distillation-488ffd8e5938\n",
        "\n",
        "For this training, we‚Äôll modify one thing:\n",
        "- The total training steps hyperparameter is too high since we can hit the benchmark (mean reward = 1.75) in only 1M training steps.\n",
        "üëâ To do that, we go to config/ppo/PyramidsRND.yaml,**and modify these to max_steps to 1000000.**\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/pyramids-config.png\" alt=\"Pyramids config\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RI-5aPL7BWVk"
      },
      "source": [
        "As an experimentation, you should also try to modify some other hyperparameters, Unity provides a very [good documentation explaining each of them here](https://github.com/Unity-Technologies/ml-agents/blob/main/docs/Training-Configuration-File.md).\n",
        "\n",
        "We‚Äôre now ready to train our agent üî•."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5hr1rvIBdZH"
      },
      "source": [
        "### Train the agent\n",
        "\n",
        "The training will take 30 to 45min depending on your machine, go take a ‚òïÔ∏èyou deserve it ü§ó."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fXi4-IaHBhqD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3234cc0d-c85c-4448-fec3-4804f6733920"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:451.)\n",
            "  _C._set_default_tensor_type(t)\n",
            "2024-01-20 13:41:22.082957: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-01-20 13:41:22.170688: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "            ‚îê  ‚ïñ\n",
            "        ‚ïì‚ïñ‚ï¨‚îÇ‚ï°  ‚îÇ‚îÇ‚ï¨‚ïñ‚ïñ\n",
            "    ‚ïì‚ïñ‚ï¨‚îÇ‚îÇ‚îÇ‚îÇ‚îÇ‚îò  ‚ï¨‚îÇ‚îÇ‚îÇ‚îÇ‚îÇ‚ï¨‚ïñ\n",
            " ‚ïñ‚ï¨‚îÇ‚îÇ‚îÇ‚îÇ‚îÇ‚ï¨‚ïú        ‚ïô‚ï¨‚îÇ‚îÇ‚îÇ‚îÇ‚îÇ‚ïñ‚ïñ                               ‚ïó‚ïó‚ïó\n",
            " ‚ï¨‚ï¨‚ï¨‚ï¨‚ïñ‚îÇ‚îÇ‚ï¶‚ïñ        ‚ïñ‚ï¨‚îÇ‚îÇ‚ïó‚ï£‚ï£‚ï£‚ï¨      ‚ïü‚ï£‚ï£‚ï¨    ‚ïü‚ï£‚ï£‚ï£             ‚ïú‚ïú‚ïú  ‚ïü‚ï£‚ï£\n",
            " ‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ïñ‚îÇ‚ï¨‚ïñ‚ïñ‚ïì‚ï¨‚ï™‚îÇ‚ïì‚ï£‚ï£‚ï£‚ï£‚ï£‚ï£‚ï£‚ï¨      ‚ïü‚ï£‚ï£‚ï¨    ‚ïü‚ï£‚ï£‚ï£ ‚ïí‚ï£‚ï£‚ïñ‚ïó‚ï£‚ï£‚ï£‚ïó   ‚ï£‚ï£‚ï£ ‚ï£‚ï£‚ï£‚ï£‚ï£‚ï£ ‚ïü‚ï£‚ï£‚ïñ   ‚ï£‚ï£‚ï£\n",
            " ‚ï¨‚ï¨‚ï¨‚ï¨‚îê  ‚ïô‚ï¨‚ï¨‚ï¨‚ï¨‚îÇ‚ïì‚ï£‚ï£‚ï£‚ïù‚ïú  ‚ï´‚ï£‚ï£‚ï£‚ï¨      ‚ïü‚ï£‚ï£‚ï¨    ‚ïü‚ï£‚ï£‚ï£ ‚ïü‚ï£‚ï£‚ï£‚ïô ‚ïô‚ï£‚ï£‚ï£  ‚ï£‚ï£‚ï£ ‚ïô‚ïü‚ï£‚ï£‚ïú‚ïô  ‚ï´‚ï£‚ï£  ‚ïü‚ï£‚ï£\n",
            " ‚ï¨‚ï¨‚ï¨‚ï¨‚îê     ‚ïô‚ï¨‚ï¨‚ï£‚ï£      ‚ï´‚ï£‚ï£‚ï£‚ï¨      ‚ïü‚ï£‚ï£‚ï¨    ‚ïü‚ï£‚ï£‚ï£ ‚ïü‚ï£‚ï£‚ï¨   ‚ï£‚ï£‚ï£  ‚ï£‚ï£‚ï£  ‚ïü‚ï£‚ï£     ‚ï£‚ï£‚ï£‚îå‚ï£‚ï£‚ïú\n",
            " ‚ï¨‚ï¨‚ï¨‚ïú       ‚ï¨‚ï¨‚ï£‚ï£      ‚ïô‚ïù‚ï£‚ï£‚ï¨      ‚ïô‚ï£‚ï£‚ï£‚ïó‚ïñ‚ïì‚ïó‚ï£‚ï£‚ï£‚ïú ‚ïü‚ï£‚ï£‚ï¨   ‚ï£‚ï£‚ï£  ‚ï£‚ï£‚ï£  ‚ïü‚ï£‚ï£‚ï¶‚ïì    ‚ï£‚ï£‚ï£‚ï£‚ï£\n",
            " ‚ïô   ‚ïì‚ï¶‚ïñ    ‚ï¨‚ï¨‚ï£‚ï£   ‚ïì‚ïó‚ïó‚ïñ            ‚ïô‚ïù‚ï£‚ï£‚ï£‚ï£‚ïù‚ïú   ‚ïò‚ïù‚ïù‚ïú   ‚ïù‚ïù‚ïù  ‚ïù‚ïù‚ïù   ‚ïô‚ï£‚ï£‚ï£    ‚ïü‚ï£‚ï£‚ï£\n",
            "   ‚ï©‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¶‚ï¶‚ï¨‚ï¨‚ï£‚ï£‚ïó‚ï£‚ï£‚ï£‚ï£‚ï£‚ï£‚ï£‚ïù                                             ‚ï´‚ï£‚ï£‚ï£‚ï£\n",
            "      ‚ïô‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï£‚ï£‚ï£‚ï£‚ï£‚ï£‚ïù‚ïú\n",
            "          ‚ïô‚ï¨‚ï¨‚ï¨‚ï£‚ï£‚ï£‚ïú\n",
            "             ‚ïô\n",
            "        \n",
            " Version information:\n",
            "  ml-agents: 1.1.0.dev0,\n",
            "  ml-agents-envs: 1.1.0.dev0,\n",
            "  Communicator API: 1.5.0,\n",
            "  PyTorch: 2.1.2+cu121\n",
            "[INFO] Connected to Unity environment with package version 2.2.1-exp.1 and communication version 1.5.0\n",
            "[INFO] Connected new brain: Pyramids?team=0\n",
            "[INFO] Hyperparameters for behavior name Pyramids: \n",
            "\ttrainer_type:\tppo\n",
            "\thyperparameters:\t\n",
            "\t  batch_size:\t128\n",
            "\t  buffer_size:\t2048\n",
            "\t  learning_rate:\t0.0003\n",
            "\t  beta:\t0.01\n",
            "\t  epsilon:\t0.2\n",
            "\t  lambd:\t0.95\n",
            "\t  num_epoch:\t3\n",
            "\t  shared_critic:\tFalse\n",
            "\t  learning_rate_schedule:\tlinear\n",
            "\t  beta_schedule:\tlinear\n",
            "\t  epsilon_schedule:\tlinear\n",
            "\tcheckpoint_interval:\t500000\n",
            "\tnetwork_settings:\t\n",
            "\t  normalize:\tFalse\n",
            "\t  hidden_units:\t512\n",
            "\t  num_layers:\t2\n",
            "\t  vis_encode_type:\tsimple\n",
            "\t  memory:\tNone\n",
            "\t  goal_conditioning_type:\thyper\n",
            "\t  deterministic:\tFalse\n",
            "\treward_signals:\t\n",
            "\t  extrinsic:\t\n",
            "\t    gamma:\t0.99\n",
            "\t    strength:\t1.0\n",
            "\t    network_settings:\t\n",
            "\t      normalize:\tFalse\n",
            "\t      hidden_units:\t128\n",
            "\t      num_layers:\t2\n",
            "\t      vis_encode_type:\tsimple\n",
            "\t      memory:\tNone\n",
            "\t      goal_conditioning_type:\thyper\n",
            "\t      deterministic:\tFalse\n",
            "\t  rnd:\t\n",
            "\t    gamma:\t0.99\n",
            "\t    strength:\t0.01\n",
            "\t    network_settings:\t\n",
            "\t      normalize:\tFalse\n",
            "\t      hidden_units:\t64\n",
            "\t      num_layers:\t3\n",
            "\t      vis_encode_type:\tsimple\n",
            "\t      memory:\tNone\n",
            "\t      goal_conditioning_type:\thyper\n",
            "\t      deterministic:\tFalse\n",
            "\t    learning_rate:\t0.0001\n",
            "\t    encoding_size:\tNone\n",
            "\tinit_path:\tNone\n",
            "\tkeep_checkpoints:\t5\n",
            "\teven_checkpoints:\tFalse\n",
            "\tmax_steps:\t1000000\n",
            "\ttime_horizon:\t128\n",
            "\tsummary_freq:\t30000\n",
            "\tthreaded:\tFalse\n",
            "\tself_play:\tNone\n",
            "\tbehavioral_cloning:\tNone\n",
            "[INFO] Pyramids. Step: 30000. Time Elapsed: 103.457 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 30000. Time Elapsed: 103.457 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "[INFO] Pyramids. Step: 60000. Time Elapsed: 201.032 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 60000. Time Elapsed: 201.032 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n",
            "[INFO] Pyramids. Step: 90000. Time Elapsed: 306.084 s. Mean Reward: -0.927. Std of Reward: 0.406. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 90000. Time Elapsed: 306.084 s. Mean Reward: -0.927. Std of Reward: 0.406. Training.\n",
            "[INFO] Pyramids. Step: 120000. Time Elapsed: 410.030 s. Mean Reward: -0.935. Std of Reward: 0.365. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 120000. Time Elapsed: 410.030 s. Mean Reward: -0.935. Std of Reward: 0.365. Training.\n",
            "[INFO] Pyramids. Step: 150000. Time Elapsed: 518.136 s. Mean Reward: -0.933. Std of Reward: 0.374. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 150000. Time Elapsed: 518.136 s. Mean Reward: -0.933. Std of Reward: 0.374. Training.\n",
            "[INFO] Pyramids. Step: 180000. Time Elapsed: 622.499 s. Mean Reward: -0.917. Std of Reward: 0.461. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 180000. Time Elapsed: 622.499 s. Mean Reward: -0.917. Std of Reward: 0.461. Training.\n",
            "[INFO] Pyramids. Step: 210000. Time Elapsed: 738.056 s. Mean Reward: -0.567. Std of Reward: 0.939. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 210000. Time Elapsed: 738.056 s. Mean Reward: -0.567. Std of Reward: 0.939. Training.\n",
            "[INFO] Pyramids. Step: 240000. Time Elapsed: 852.270 s. Mean Reward: -0.443. Std of Reward: 0.988. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 240000. Time Elapsed: 852.270 s. Mean Reward: -0.443. Std of Reward: 0.988. Training.\n",
            "[INFO] Pyramids. Step: 270000. Time Elapsed: 974.241 s. Mean Reward: -0.065. Std of Reward: 1.190. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 270000. Time Elapsed: 974.241 s. Mean Reward: -0.065. Std of Reward: 1.190. Training.\n",
            "[INFO] Pyramids. Step: 300000. Time Elapsed: 1093.719 s. Mean Reward: -0.121. Std of Reward: 1.146. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 300000. Time Elapsed: 1093.719 s. Mean Reward: -0.121. Std of Reward: 1.146. Training.\n",
            "[INFO] Pyramids. Step: 330000. Time Elapsed: 1219.655 s. Mean Reward: -0.072. Std of Reward: 1.197. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 330000. Time Elapsed: 1219.655 s. Mean Reward: -0.072. Std of Reward: 1.197. Training.\n",
            "[INFO] Pyramids. Step: 360000. Time Elapsed: 1334.170 s. Mean Reward: 0.035. Std of Reward: 1.221. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 360000. Time Elapsed: 1334.170 s. Mean Reward: 0.035. Std of Reward: 1.221. Training.\n",
            "[INFO] Pyramids. Step: 390000. Time Elapsed: 1454.380 s. Mean Reward: 0.056. Std of Reward: 1.193. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 390000. Time Elapsed: 1454.380 s. Mean Reward: 0.056. Std of Reward: 1.193. Training.\n",
            "[INFO] Pyramids. Step: 420000. Time Elapsed: 1570.793 s. Mean Reward: 0.643. Std of Reward: 1.160. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 420000. Time Elapsed: 1570.793 s. Mean Reward: 0.643. Std of Reward: 1.160. Training.\n",
            "[INFO] Pyramids. Step: 450000. Time Elapsed: 1685.202 s. Mean Reward: 0.839. Std of Reward: 1.126. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 450000. Time Elapsed: 1685.202 s. Mean Reward: 0.839. Std of Reward: 1.126. Training.\n",
            "[INFO] Pyramids. Step: 480000. Time Elapsed: 1811.635 s. Mean Reward: 0.985. Std of Reward: 1.077. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 480000. Time Elapsed: 1811.635 s. Mean Reward: 0.985. Std of Reward: 1.077. Training.\n",
            "[INFO] Exported results/Pyramids Training/Pyramids/Pyramids-499964.onnx\n",
            "INFO:mlagents.trainers.torch_entities.model_serialization:Exported results/Pyramids Training/Pyramids/Pyramids-499964.onnx\n",
            "[INFO] Pyramids. Step: 510000. Time Elapsed: 1934.411 s. Mean Reward: 1.060. Std of Reward: 1.025. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 510000. Time Elapsed: 1934.411 s. Mean Reward: 1.060. Std of Reward: 1.025. Training.\n",
            "[INFO] Pyramids. Step: 540000. Time Elapsed: 2055.967 s. Mean Reward: 1.092. Std of Reward: 0.995. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 540000. Time Elapsed: 2055.967 s. Mean Reward: 1.092. Std of Reward: 0.995. Training.\n",
            "[INFO] Pyramids. Step: 570000. Time Elapsed: 2181.521 s. Mean Reward: 1.232. Std of Reward: 0.976. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 570000. Time Elapsed: 2181.521 s. Mean Reward: 1.232. Std of Reward: 0.976. Training.\n",
            "[INFO] Pyramids. Step: 600000. Time Elapsed: 2309.657 s. Mean Reward: 1.197. Std of Reward: 0.986. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 600000. Time Elapsed: 2309.657 s. Mean Reward: 1.197. Std of Reward: 0.986. Training.\n",
            "[INFO] Pyramids. Step: 630000. Time Elapsed: 2439.532 s. Mean Reward: 1.335. Std of Reward: 0.818. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 630000. Time Elapsed: 2439.532 s. Mean Reward: 1.335. Std of Reward: 0.818. Training.\n",
            "[INFO] Pyramids. Step: 660000. Time Elapsed: 2566.568 s. Mean Reward: 1.442. Std of Reward: 0.694. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 660000. Time Elapsed: 2566.568 s. Mean Reward: 1.442. Std of Reward: 0.694. Training.\n",
            "[INFO] Pyramids. Step: 690000. Time Elapsed: 2693.690 s. Mean Reward: 1.488. Std of Reward: 0.696. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 690000. Time Elapsed: 2693.690 s. Mean Reward: 1.488. Std of Reward: 0.696. Training.\n",
            "[INFO] Pyramids. Step: 720000. Time Elapsed: 2820.747 s. Mean Reward: 1.485. Std of Reward: 0.728. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 720000. Time Elapsed: 2820.747 s. Mean Reward: 1.485. Std of Reward: 0.728. Training.\n",
            "[INFO] Pyramids. Step: 750000. Time Elapsed: 2949.759 s. Mean Reward: 1.467. Std of Reward: 0.726. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 750000. Time Elapsed: 2949.759 s. Mean Reward: 1.467. Std of Reward: 0.726. Training.\n",
            "[INFO] Pyramids. Step: 780000. Time Elapsed: 3078.231 s. Mean Reward: 1.454. Std of Reward: 0.775. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 780000. Time Elapsed: 3078.231 s. Mean Reward: 1.454. Std of Reward: 0.775. Training.\n",
            "[INFO] Pyramids. Step: 810000. Time Elapsed: 3209.002 s. Mean Reward: 1.650. Std of Reward: 0.203. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 810000. Time Elapsed: 3209.002 s. Mean Reward: 1.650. Std of Reward: 0.203. Training.\n",
            "[INFO] Pyramids. Step: 840000. Time Elapsed: 3344.352 s. Mean Reward: 1.625. Std of Reward: 0.494. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 840000. Time Elapsed: 3344.352 s. Mean Reward: 1.625. Std of Reward: 0.494. Training.\n",
            "[INFO] Pyramids. Step: 870000. Time Elapsed: 3484.920 s. Mean Reward: 1.651. Std of Reward: 0.477. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 870000. Time Elapsed: 3484.920 s. Mean Reward: 1.651. Std of Reward: 0.477. Training.\n",
            "[INFO] Pyramids. Step: 900000. Time Elapsed: 3615.188 s. Mean Reward: 1.681. Std of Reward: 0.180. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 900000. Time Elapsed: 3615.188 s. Mean Reward: 1.681. Std of Reward: 0.180. Training.\n",
            "[INFO] Pyramids. Step: 930000. Time Elapsed: 3752.056 s. Mean Reward: 1.682. Std of Reward: 0.314. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 930000. Time Elapsed: 3752.056 s. Mean Reward: 1.682. Std of Reward: 0.314. Training.\n",
            "[INFO] Pyramids. Step: 960000. Time Elapsed: 3894.772 s. Mean Reward: 1.626. Std of Reward: 0.604. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 960000. Time Elapsed: 3894.772 s. Mean Reward: 1.626. Std of Reward: 0.604. Training.\n",
            "[INFO] Pyramids. Step: 990000. Time Elapsed: 4035.218 s. Mean Reward: 1.638. Std of Reward: 0.548. Training.\n",
            "INFO:mlagents.trainers.stats:Pyramids. Step: 990000. Time Elapsed: 4035.218 s. Mean Reward: 1.638. Std of Reward: 0.548. Training.\n",
            "[INFO] Exported results/Pyramids Training/Pyramids/Pyramids-999994.onnx\n",
            "INFO:mlagents.trainers.torch_entities.model_serialization:Exported results/Pyramids Training/Pyramids/Pyramids-999994.onnx\n",
            "[INFO] Exported results/Pyramids Training/Pyramids/Pyramids-1000122.onnx\n",
            "INFO:mlagents.trainers.torch_entities.model_serialization:Exported results/Pyramids Training/Pyramids/Pyramids-1000122.onnx\n",
            "[INFO] Copied results/Pyramids Training/Pyramids/Pyramids-1000122.onnx to results/Pyramids Training/Pyramids.onnx.\n",
            "INFO:mlagents.trainers.model_saver.torch_model_saver:Copied results/Pyramids Training/Pyramids/Pyramids-1000122.onnx to results/Pyramids Training/Pyramids.onnx.\n"
          ]
        }
      ],
      "source": [
        "!mlagents-learn ./config/ppo/PyramidsRND.yaml --env=./training-envs-executables/linux/Pyramids/Pyramids --run-id=\"Pyramids Training\" --no-graphics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txonKxuSByut"
      },
      "source": [
        "### Push the agent to the ü§ó Hub\n",
        "\n",
        "- Now that we trained our agent, we‚Äôre **ready to push it to the Hub to be able to visualize it playing on your browserüî•.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mlagents-push-to-hf --run-id=\"Pyramids Training\" --local-dir=\"./results/Pyramids Training\" --repo-id=\"k0T0z/ppo-PyramidsRND\" --commit-message=\"First Push\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPEMuj79XpHL",
        "outputId": "fb2db827-39e8-4c6f-ed37-a78f949dce28"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] This function will create a model card and upload your Pyramids Training into HuggingFace Hub. This is a work in progress: If you encounter a bug, please send open an issue\n",
            "[INFO] Pushing repo Pyramids Training to the Hugging Face Hub\n",
            "Pyramids-499964.onnx:   0% 0.00/1.42M [00:00<?, ?B/s]\n",
            "\n",
            "Upload 9 LFS files:   0% 0/9 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Pyramids-1000122.pt:   0% 0.00/8.66M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "Pyramids.onnx:   0% 0.00/1.42M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Pyramids.onnx:   0% 0.00/1.42M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Pyramids-499964.pt:   0% 0.00/8.66M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Pyramids-499964.onnx:   1% 16.4k/1.42M [00:00<00:49, 28.2kB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Pyramids-499964.pt:   0% 16.4k/8.66M [00:00<05:09, 27.9kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Pyramids.onnx:   1% 16.4k/1.42M [00:00<00:50, 27.7kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Pyramids-1000122.pt:   0% 16.4k/8.66M [00:00<05:18, 27.2kB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Pyramids-499964.pt:  66% 5.72M/8.66M [00:00<00:00, 10.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Pyramids-499964.onnx: 100% 1.42M/1.42M [00:00<00:00, 1.76MB/s]\n",
            "Pyramids.onnx: 100% 1.42M/1.42M [00:00<00:00, 1.69MB/s]\n",
            "Pyramids.onnx: 100% 1.42M/1.42M [00:00<00:00, 1.57MB/s]\n",
            "Pyramids-1000122.pt: 100% 8.66M/8.66M [00:01<00:00, 8.62MB/s]\n",
            "Pyramids-499964.pt: 100% 8.66M/8.66M [00:01<00:00, 8.39MB/s]\n",
            "Pyramids-999994.pt:   0% 0.00/8.66M [00:00<?, ?B/s]\n",
            "checkpoint.pt:   0% 0.00/8.65M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Upload 9 LFS files:  11% 1/9 [00:01<00:11,  1.47s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Pyramids-999994.pt:  81% 7.00M/8.66M [00:00<00:00, 67.8MB/s]\n",
            "checkpoint.pt:  55% 4.77M/8.65M [00:00<00:00, 42.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Pyramids.onnx:   0% 0.00/1.42M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Pyramids-999994.pt: 100% 8.66M/8.66M [00:00<00:00, 25.9MB/s]\n",
            "events.out.tfevents.1705758083.80e242070a31.28929.0: 100% 305k/305k [00:00<00:00, 1.22MB/s]\n",
            "Pyramids.onnx: 100% 1.42M/1.42M [00:00<00:00, 5.96MB/s]\n",
            "\n",
            "\n",
            "checkpoint.pt: 100% 8.65M/8.65M [00:00<00:00, 21.1MB/s]\n",
            "\n",
            "\n",
            "Upload 9 LFS files: 100% 9/9 [00:01<00:00,  4.65it/s]\n",
            "[INFO] Your model is pushed to the hub. You can view your model here: https://huggingface.co/k0T0z/ppo-PyramidsRND\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiEQbv7rB4mU"
      },
      "outputs": [],
      "source": [
        "!mlagents-push-to-hf  --run-id= # Add your run id  --local-dir= # Your local dir  --repo-id= # Your repo id  --commit-message= # Your commit message"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aZfgxo-CDeQ"
      },
      "source": [
        "### Watch your agent playing üëÄ\n",
        "\n",
        "üëâ https://huggingface.co/spaces/unity/ML-Agents-Pyramids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGG_oq2n0wjB"
      },
      "source": [
        "### üéÅ Bonus: Why not train on another environment?\n",
        "Now that you know how to train an agent using MLAgents, **why not try another environment?**\n",
        "\n",
        "MLAgents provides 17 different and we‚Äôre building some custom ones. The best way to learn is to try things of your own, have fun.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSAkJxSr0z6-"
      },
      "source": [
        "![cover](https://miro.medium.com/max/1400/0*xERdThTRRM2k_U9f.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiyF4FX-04JB"
      },
      "source": [
        "You have the full list of the Unity official environments here üëâ https://github.com/Unity-Technologies/ml-agents/blob/develop/docs/Learning-Environment-Examples.md\n",
        "\n",
        "For the demos to visualize your agent üëâ https://huggingface.co/unity\n",
        "\n",
        "For now we have integrated:\n",
        "- [Worm](https://huggingface.co/spaces/unity/ML-Agents-Worm) demo where you teach a **worm to crawl**.\n",
        "- [Walker](https://huggingface.co/spaces/unity/ML-Agents-Walker) demo where you teach an agent **to walk towards a goal**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PI6dPWmh064H"
      },
      "source": [
        "That‚Äôs all for today. Congrats on finishing this tutorial!\n",
        "\n",
        "The best way to learn is to practice and try stuff. Why not try another environment? ML-Agents has 17 different environments, but you can also create your own? Check the documentation and have fun!\n",
        "\n",
        "See you on Unit 6 üî•,\n",
        "\n",
        "## Keep Learning, Stay  awesome ü§ó"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "62f519e8272047bb8e49db3dd72f5f2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e3a523c772649e0b4d883d2b8205cd9",
              "IPY_MODEL_938b25a55b9641c3a10977f0493f0c05",
              "IPY_MODEL_cacb6da400e244afb5993cbad9a72cde",
              "IPY_MODEL_0df8266a32d346dcb02d701295f8320a"
            ],
            "layout": "IPY_MODEL_7c9dde65cef54d2e9cb70050ebe18667"
          }
        },
        "82a2a25521b345e5aa486c5d2ef6d745": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_299a149071a247eda185cc9cd3b6e116",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_21ffa32a2ecd48c59ad292a0fa94d734",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "52d68334d023472eab29b547c42a18aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_9e6c43e987594906986d6833298ff6cc",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0ef680020ac24a8db995071f746b4f12",
            "value": ""
          }
        },
        "196dc2e8597f4a7faf021fe810afb55c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_219de625c73d45debc316f97c8832022",
            "style": "IPY_MODEL_e00504d9730a40dd9eecea5bfc965774",
            "value": true
          }
        },
        "03416377f667417b88848134a3023c91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_c388b55f5ad34d1b900fcc24f63c45fd",
            "style": "IPY_MODEL_7d6329924321458e81106454a1475812",
            "tooltip": ""
          }
        },
        "6444a8c6043c4063a8cc9cf60d2531b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e9823b18d524d3baed640df8a161b97",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9269a0159ba7449a8575ef27d5e02e92",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "7c9dde65cef54d2e9cb70050ebe18667": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "299a149071a247eda185cc9cd3b6e116": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21ffa32a2ecd48c59ad292a0fa94d734": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e6c43e987594906986d6833298ff6cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ef680020ac24a8db995071f746b4f12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "219de625c73d45debc316f97c8832022": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e00504d9730a40dd9eecea5bfc965774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c388b55f5ad34d1b900fcc24f63c45fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d6329924321458e81106454a1475812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "3e9823b18d524d3baed640df8a161b97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9269a0159ba7449a8575ef27d5e02e92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32f52c52b4ea49bb884ffc188dc095e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6d9e6b7ecc244d9b7f04e1ac1127446",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8f75a35d0921409b81f8e6a2fc217d32",
            "value": "Connecting..."
          }
        },
        "a6d9e6b7ecc244d9b7f04e1ac1127446": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f75a35d0921409b81f8e6a2fc217d32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e3a523c772649e0b4d883d2b8205cd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3095c99248c3424ab51f7e0c21e85124",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6e32afbc49d34336b2c68e31074ef0c7",
            "value": "Token is valid (permission: write)."
          }
        },
        "938b25a55b9641c3a10977f0493f0c05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_645043d32a774126ae48fe871286d047",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_57b27caad64d40859fbadf156112c315",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "cacb6da400e244afb5993cbad9a72cde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd891ed6dc5c4163a01546e924b5ce8a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_56faf8ceb036490aaec12a84d64138f2",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "0df8266a32d346dcb02d701295f8320a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e736551157a4415baafd60f3d98f0b4f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_eb28509222c34dc183d09586819fd9e6",
            "value": "Login successful"
          }
        },
        "3095c99248c3424ab51f7e0c21e85124": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e32afbc49d34336b2c68e31074ef0c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "645043d32a774126ae48fe871286d047": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57b27caad64d40859fbadf156112c315": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd891ed6dc5c4163a01546e924b5ce8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56faf8ceb036490aaec12a84d64138f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e736551157a4415baafd60f3d98f0b4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb28509222c34dc183d09586819fd9e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}